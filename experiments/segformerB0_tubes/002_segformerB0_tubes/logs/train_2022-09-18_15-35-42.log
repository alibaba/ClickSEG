(INFO) 2022-09-18 15:35:42: Number of GPUs: 1
(INFO) 2022-09-18 15:35:42: Run experiment with config:
(INFO) 2022-09-18 15:35:42: {   'CHECKPOINTS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/002_segformerB0_tubes/checkpoints'),
    'EXP_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/002_segformerB0_tubes'),
    'LOGS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/002_segformerB0_tubes/logs'),
    'VIS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/002_segformerB0_tubes/vis'),
    'batch_size': 128,
    'dataset_path': '/nfs/hpc/share/wigginno/branching/branching_retinal_mix_dataset',
    'device': device(type='cuda', index=0),
    'distributed': False,
    'exp_name': 'segformerB0_tubes',
    'gpu_ids': [0],
    'gpus': '0',
    'local_rank': 0,
    'model_path': '/nfs/hpc/share/wigginno/branching/ClickSEG/models/segformerB0_tubes.py',
    'multi_gpu': False,
    'ngpus': 1,
    'pretrained_weights': '/nfs/hpc/share/wigginno/branching/ClickSEG/pretrained/segformer_b0/last_checkpoint.pth',
    'resume_exp': None,
    'resume_prefix': 'latest',
    'start_epoch': 0,
    'temp_model_path': '',
    'weights': None,
    'workers': 94}
(INFO) 2022-09-18 15:35:46: Dataset of 1766 samples was loaded for training.
(INFO) 2022-09-18 15:35:46: Dataset of 533 samples was loaded for validation.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.sr.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.sr.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.norm.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.norm.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm3.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm3.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.q.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.q.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.kv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.kv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.proj.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.proj.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm4.weight" parameter.
(INFO) 2022-09-18 15:35:46: Applied lr_mult=0.1 to "feature_extractor.backbone.norm4.bias" parameter.
(INFO) 2022-09-18 15:35:46: SegFormerModel(
  (maps_transform): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.2)
    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (3): ScaleLayer()
  )
  (dist_maps_2): DistMaps()
  (dist_maps_5): DistMaps()
  (feature_extractor): SegFormer(
    (backbone): mit_b0(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed_side1): OverlapPatchEmbed(
        (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=32, out_features=32, bias=True)
            (kv): Linear(in_features=32, out_features=64, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=128, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            )
            (act): GELU()
            (fc2): Linear(in_features=128, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=32, out_features=32, bias=True)
            (kv): Linear(in_features=32, out_features=64, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=128, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            )
            (act): GELU()
            (fc2): Linear(in_features=128, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=160, out_features=160, bias=True)
            (kv): Linear(in_features=160, out_features=320, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=160, out_features=160, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=160, out_features=640, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
            )
            (act): GELU()
            (fc2): Linear(in_features=640, out_features=160, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=160, out_features=160, bias=True)
            (kv): Linear(in_features=160, out_features=320, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=160, out_features=160, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=160, out_features=640, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
            )
            (act): GELU()
            (fc2): Linear(in_features=640, out_features=160, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (kv): Linear(in_features=256, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            )
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (kv): Linear(in_features=256, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            )
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): SegFormerHead(
      (linear_c4): MLP(
        (proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (linear_c3): MLP(
        (proj): Linear(in_features=160, out_features=256, bias=True)
      )
      (linear_c2): MLP(
        (proj): Linear(in_features=64, out_features=256, bias=True)
      )
      (linear_c1): MLP(
        (proj): Linear(in_features=32, out_features=256, bias=True)
      )
      (linear_fuse): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (linear_pred): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
  )
  (dist_maps_base): DistMaps()
  (dist_maps_refine): DistMaps()
  (refiner): RefineLayer(
    (image_conv1): ConvModule(
      (conv): Conv2d(6, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (image_conv2): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (image_conv3): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion): ConvModule(
      (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion2): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion3): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (feature_gate): Sequential(
      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): Sigmoid()
    )
    (refine_pred): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (refine_trimap): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
(INFO) 2022-09-18 15:35:46: Model: isegm.model.is_segformer_model.SegFormerModel
pipeline_version       = s2          
model_version          = b0          
use_leaky_relu         = True        
use_rgb_conv           = False       
use_disks              = True        
norm_radius            = 5           
binary_prev_mask       = False       
with_prev_mask         = True        
with_aux_output        = True        
feature_stride         = 4            (default)
backbone_lr_mult       = 0.1          (default)
norm_layer             = BatchNorm2d  (default)
cpu_dist_maps          = False        (default)
clicks_groups          = None         (default)
conv_extend            = False        (default)
norm_mean_std          = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) (default)

(INFO) 2022-09-18 15:35:46: Starting Epoch: 0
(INFO) 2022-09-18 15:35:46: Total Epochs: 230
(INFO) 2022-09-18 15:35:46: 0%|                                                                         | 0/7 [00:00<?, ?it/s]
(INFO) 2022-09-18 15:36:47: 0%|                                                                         | 0/7 [01:01<?, ?it/s]
