(INFO) 2022-09-17 20:23:28: Number of GPUs: 1
(INFO) 2022-09-17 20:23:28: Run experiment with config:
(INFO) 2022-09-17 20:23:28: {   'CHECKPOINTS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints'),
    'EXP_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes'),
    'LOGS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/logs'),
    'VIS_PATH': PosixPath('/nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/vis'),
    'batch_size': 128,
    'dataset_path': '/nfs/hpc/share/wigginno/branching/branching_retinal_mix_dataset',
    'device': device(type='cuda', index=0),
    'distributed': False,
    'exp_name': 'segformerB0_tubes',
    'gpu_ids': [0],
    'gpus': '0',
    'local_rank': 0,
    'model_path': '/nfs/hpc/share/wigginno/branching/ClickSEG/models/segformerB0_tubes.py',
    'multi_gpu': False,
    'ngpus': 1,
    'pretrained_weights': '/nfs/hpc/share/wigginno/branching/ClickSEG/pretrained/segformer_b0/last_checkpoint.pth',
    'resume_exp': '000',
    'resume_prefix': '225',
    'start_epoch': 226,
    'temp_model_path': '',
    'weights': None,
    'workers': 94}
(INFO) 2022-09-17 20:23:32: Dataset of 1766 samples was loaded for training.
(INFO) 2022-09-17 20:23:32: Dataset of 533 samples was loaded for validation.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed1.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed2.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed3.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed4.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.patch_embed_side1.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block1.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block2.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.sr.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.sr.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.norm.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.attn.norm.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block3.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm3.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm3.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.0.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.q.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.q.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.kv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.kv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.proj.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.attn.proj.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.norm2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc1.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc1.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.dwconv.dwconv.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.dwconv.dwconv.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc2.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.block4.1.mlp.fc2.bias" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm4.weight" parameter.
(INFO) 2022-09-17 20:23:32: Applied lr_mult=0.1 to "feature_extractor.backbone.norm4.bias" parameter.
(INFO) 2022-09-17 20:23:32: Load checkpoint from path: /nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints/225.pth
(INFO) 2022-09-17 20:23:32: SegFormerModel(
  (maps_transform): Sequential(
    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.2)
    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (3): ScaleLayer()
  )
  (dist_maps_2): DistMaps()
  (dist_maps_5): DistMaps()
  (feature_extractor): SegFormer(
    (backbone): mit_b0(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed_side1): OverlapPatchEmbed(
        (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=32, out_features=32, bias=True)
            (kv): Linear(in_features=32, out_features=64, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=128, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            )
            (act): GELU()
            (fc2): Linear(in_features=128, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=32, out_features=32, bias=True)
            (kv): Linear(in_features=32, out_features=64, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=32, out_features=32, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=32, out_features=128, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
            )
            (act): GELU()
            (fc2): Linear(in_features=128, out_features=32, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((32,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=160, out_features=160, bias=True)
            (kv): Linear(in_features=160, out_features=320, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=160, out_features=160, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=160, out_features=640, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
            )
            (act): GELU()
            (fc2): Linear(in_features=640, out_features=160, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=160, out_features=160, bias=True)
            (kv): Linear(in_features=160, out_features=320, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=160, out_features=160, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=160, out_features=640, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)
            )
            (act): GELU()
            (fc2): Linear(in_features=640, out_features=160, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((160,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (kv): Linear(in_features=256, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            )
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=256, out_features=256, bias=True)
            (kv): Linear(in_features=256, out_features=512, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=256, out_features=256, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=256, out_features=1024, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
            )
            (act): GELU()
            (fc2): Linear(in_features=1024, out_features=256, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): SegFormerHead(
      (linear_c4): MLP(
        (proj): Linear(in_features=256, out_features=256, bias=True)
      )
      (linear_c3): MLP(
        (proj): Linear(in_features=160, out_features=256, bias=True)
      )
      (linear_c2): MLP(
        (proj): Linear(in_features=64, out_features=256, bias=True)
      )
      (linear_c1): MLP(
        (proj): Linear(in_features=32, out_features=256, bias=True)
      )
      (linear_fuse): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (linear_pred): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
    )
  )
  (dist_maps_base): DistMaps()
  (dist_maps_refine): DistMaps()
  (refiner): RefineLayer(
    (image_conv1): ConvModule(
      (conv): Conv2d(6, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (image_conv2): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (image_conv3): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion): ConvModule(
      (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion2): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (refine_fusion3): XConvBnRelu(
      (conv3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)
      (conv1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
      (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation): ReLU()
    )
    (feature_gate): Sequential(
      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): Sigmoid()
    )
    (refine_pred): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (refine_trimap): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
(INFO) 2022-09-17 20:23:32: Model: isegm.model.is_segformer_model.SegFormerModel
pipeline_version       = s2          
model_version          = b0          
use_leaky_relu         = True        
use_rgb_conv           = False       
use_disks              = True        
norm_radius            = 5           
binary_prev_mask       = False       
with_prev_mask         = True        
with_aux_output        = True        
feature_stride         = 4            (default)
backbone_lr_mult       = 0.1          (default)
norm_layer             = BatchNorm2d  (default)
cpu_dist_maps          = False        (default)
clicks_groups          = None         (default)
conv_extend            = False        (default)
norm_mean_std          = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) (default)

(INFO) 2022-09-17 20:23:32: Starting Epoch: 226
(INFO) 2022-09-17 20:23:32: Total Epochs: 230
(INFO) 2022-09-17 20:23:32: 0%|                                                                        | 0/39 [00:00<?, ?it/s]
(INFO) 2022-09-17 20:24:20: Epoch 226, training loss 0.9801:   0%|                                       | 0/39 [00:48<?, ?it/s]
(INFO) 2022-09-17 20:24:27: Epoch 226, training loss 0.9821:   5%|#5                             | 2/39 [00:54<12:32, 20.35s/it]
(INFO) 2022-09-17 20:24:32: Epoch 226, training loss 0.9768:  13%|###9                           | 5/39 [01:00<03:34,  6.31s/it]
(INFO) 2022-09-17 20:24:39: Epoch 226, training loss 0.9793:  23%|#######1                       | 9/39 [01:06<01:17,  2.59s/it]
(INFO) 2022-09-17 20:24:44: Epoch 226, training loss 0.9799:  31%|#########2                    | 12/39 [01:12<01:03,  2.35s/it]
(INFO) 2022-09-17 20:24:50: Epoch 226, training loss 0.9790:  44%|#############                 | 17/39 [01:18<00:32,  1.47s/it]
(INFO) 2022-09-17 20:24:56: Epoch 226, training loss 0.9774:  51%|###############3              | 20/39 [01:23<00:28,  1.48s/it]
(INFO) 2022-09-17 20:25:03: Epoch 226, training loss 0.9764:  62%|##################4           | 24/39 [01:30<00:25,  1.70s/it]
(INFO) 2022-09-17 20:25:09: Epoch 226, training loss 0.9760:  72%|#####################5        | 28/39 [01:37<00:16,  1.51s/it]
(INFO) 2022-09-17 20:25:15: Epoch 226, training loss 0.9742:  79%|#######################8      | 31/39 [01:42<00:14,  1.75s/it]
(INFO) 2022-09-17 20:25:22: Epoch 226, training loss 0.9723:  87%|##########################1   | 34/39 [01:49<00:10,  2.06s/it]
(INFO) 2022-09-17 20:25:27: Epoch 226, training loss 0.9727:  97%|#############################2| 38/39 [01:55<00:01,  1.59s/it]
(INFO) 2022-09-17 20:25:28: Save checkpoint to /nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints/last_checkpoint.pth
(INFO) 2022-09-17 20:26:07: Epoch 227, training loss 0.9729:   0%|                                       | 0/39 [00:38<?, ?it/s]
(INFO) 2022-09-17 20:26:14: Epoch 227, training loss 0.9702:   8%|##3                            | 3/39 [00:45<06:16, 10.44s/it]
(INFO) 2022-09-17 20:26:20: Epoch 227, training loss 0.9688:  18%|#####5                         | 7/39 [00:52<01:34,  2.95s/it]
(INFO) 2022-09-17 20:26:26: Epoch 227, training loss 0.9745:  28%|########4                     | 11/39 [00:58<00:51,  1.83s/it]
(INFO) 2022-09-17 20:26:32: Epoch 227, training loss 0.9723:  38%|###########5                  | 15/39 [01:03<00:34,  1.45s/it]
(INFO) 2022-09-17 20:26:37: Epoch 227, training loss 0.9732:  46%|#############8                | 18/39 [01:09<00:39,  1.90s/it]
(INFO) 2022-09-17 20:26:42: Epoch 227, training loss 0.9735:  54%|################1             | 21/39 [01:14<00:28,  1.60s/it]
(INFO) 2022-09-17 20:26:49: Epoch 227, training loss 0.9714:  64%|###################2          | 25/39 [01:21<00:24,  1.79s/it]
(INFO) 2022-09-17 20:26:55: Epoch 227, training loss 0.9693:  74%|######################3       | 29/39 [01:26<00:16,  1.62s/it]
(INFO) 2022-09-17 20:27:01: Epoch 227, training loss 0.9709:  85%|#########################3    | 33/39 [01:32<00:09,  1.54s/it]
(INFO) 2022-09-17 20:27:07: Epoch 227, training loss 0.9709:  92%|###########################6  | 36/39 [01:38<00:05,  1.76s/it]
(INFO) 2022-09-17 20:27:12: Epoch 227, training loss 0.9696: 100%|##############################| 39/39 [01:44<00:00,  2.67s/it]
(INFO) 2022-09-17 20:27:12: Save checkpoint to /nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints/last_checkpoint.pth
(INFO) 2022-09-17 20:27:50: Epoch 228, training loss 0.9676:   0%|                                       | 0/39 [00:37<?, ?it/s]
(INFO) 2022-09-17 20:27:55: Epoch 228, training loss 0.9731:   5%|#5                             | 2/39 [00:43<09:58, 16.18s/it]
(INFO) 2022-09-17 20:28:00: Epoch 228, training loss 0.9730:  15%|####7                          | 6/39 [00:48<02:05,  3.81s/it]
(INFO) 2022-09-17 20:28:06: Epoch 228, training loss 0.9685:  26%|#######6                      | 10/39 [00:53<00:55,  1.91s/it]
(INFO) 2022-09-17 20:28:12: Epoch 228, training loss 0.9698:  36%|##########7                   | 14/39 [00:59<00:41,  1.66s/it]
(INFO) 2022-09-17 20:28:18: Epoch 228, training loss 0.9690:  44%|#############                 | 17/39 [01:05<00:38,  1.74s/it]
(INFO) 2022-09-17 20:28:24: Epoch 228, training loss 0.9682:  51%|###############3              | 20/39 [01:11<00:39,  2.06s/it]
(INFO) 2022-09-17 20:28:30: Epoch 228, training loss 0.9697:  59%|#################6            | 23/39 [01:17<00:29,  1.84s/it]
(INFO) 2022-09-17 20:28:36: Epoch 228, training loss 0.9723:  69%|####################7         | 27/39 [01:23<00:19,  1.65s/it]
(INFO) 2022-09-17 20:28:41: Epoch 228, training loss 0.9725:  79%|#######################8      | 31/39 [01:28<00:10,  1.33s/it]
(INFO) 2022-09-17 20:28:47: Epoch 228, training loss 0.9728:  87%|##########################1   | 34/39 [01:34<00:08,  1.79s/it]
(INFO) 2022-09-17 20:28:53: Epoch 228, training loss 0.9727:  95%|############################4 | 37/39 [01:40<00:03,  1.85s/it]
(INFO) 2022-09-17 20:28:56: Save checkpoint to /nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints/last_checkpoint.pth
(INFO) 2022-09-17 20:29:39: Epoch 229, training loss 0.9366:   0%|                                       | 0/39 [00:43<?, ?it/s]
(INFO) 2022-09-17 20:29:45: Epoch 229, training loss 0.9686:   8%|##3                            | 3/39 [00:49<06:46, 11.30s/it]
(INFO) 2022-09-17 20:29:51: Epoch 229, training loss 0.9611:  15%|####7                          | 6/39 [00:55<02:22,  4.31s/it]
(INFO) 2022-09-17 20:29:57: Epoch 229, training loss 0.9680:  26%|#######6                      | 10/39 [01:00<00:58,  2.02s/it]
(INFO) 2022-09-17 20:30:02: Epoch 229, training loss 0.9682:  36%|##########7                   | 14/39 [01:06<00:44,  1.76s/it]
(INFO) 2022-09-17 20:30:08: Epoch 229, training loss 0.9697:  46%|#############8                | 18/39 [01:12<00:32,  1.53s/it]
(INFO) 2022-09-17 20:30:15: Epoch 229, training loss 0.9742:  59%|#################6            | 23/39 [01:18<00:21,  1.32s/it]
(INFO) 2022-09-17 20:30:22: Epoch 229, training loss 0.9708:  69%|####################7         | 27/39 [01:25<00:18,  1.55s/it]
(INFO) 2022-09-17 20:30:28: Epoch 229, training loss 0.9714:  82%|########################6     | 32/39 [01:32<00:09,  1.42s/it]
(INFO) 2022-09-17 20:30:35: Epoch 229, training loss 0.9720:  92%|###########################6  | 36/39 [01:39<00:04,  1.45s/it]
(INFO) 2022-09-17 20:30:39: Save checkpoint to /nfs/hpc/share/wigginno/branching/ClickSEG/experiments/segformerB0_tubes/000_segformerB0_tubes/checkpoints/last_checkpoint.pth
